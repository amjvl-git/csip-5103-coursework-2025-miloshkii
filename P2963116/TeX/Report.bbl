\begin{thebibliography}{1}

\bibitem{batchnorm}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift, 2015.

\bibitem{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Köpf, Edward Yang, Zach DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library,
  2019.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em J. Mach. Learn. Res.}, 15(1):1929–1958, January 2014.

\bibitem{seaborn}
Michael~L. Waskom.
\newblock seaborn: statistical data visualization.
\newblock {\em Journal of Open Source Software}, 6(60):3021, 2021.

\bibitem{pandas}
{W}es {M}c{K}inney.
\newblock {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython.
\newblock In {S}t\'efan van~der {W}alt and {J}arrod {M}illman, editors, {\em
  {P}roceedings of the 9th {P}ython in {S}cience {C}onference}, pages 56 -- 61,
  2010.

\bibitem{mnist}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\end{thebibliography}
