{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64314c6a",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Classifier\n",
    "**P2963116**\n",
    "\n",
    "### Project Brief\n",
    "1. Experience building and training Artificial Neural Networks (ANNs) for classification problems.\n",
    "2. Experience preprocessing image datasets.\n",
    "3. Experience implementing and testing neural networks in Python using PyTorch/TensorFlow.\n",
    "4. Experience comparing different neural architectures (ANN vs. CNN).\n",
    "\n",
    "The goal of this project is to create a working classifier for use on the Fashion-MNIST dataset and to compare different architectures' performance.\n",
    "I will be using *PyTorch* primarily, but also *SciKit-Learn* and *Seaborn* to create my project and display output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15369fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu130\n",
      "PyTorch working with CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import (\n",
    "    ToTensor,\n",
    "    Normalize,\n",
    "    Compose,\n",
    "    RandomAffine,\n",
    "    RandomHorizontalFlip,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducability\n",
    "random.seed(9)\n",
    "torch.manual_seed(9)\n",
    "\n",
    "# Various Preamble\n",
    "sns.set_theme()\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"PyTorch working with CUDA:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6c0dd",
   "metadata": {},
   "source": [
    "### Data import and pre-processing\n",
    "Using Torchvision's datasets module we can easily import our dataset. It also comes with the built-in method 'transform' allowing us to preprocess our data. In this case we use the ToTensor method and Normalize to store the images correctly and normalise pixel values. We will also reserve a random 20% subset of the training data for use in validation at each training step.\n",
    "\n",
    "Additionally the DataLoader allows us to automatically batch and shuffle our training and test datasets should we wish. In this case we only really need to shuffle the training data as we will not be adjusting weights using the test dataset.\n",
    "\n",
    "I have also added a couple of asserts to ensure our data was loaded correctly (through checking the shape). In this case there should be no issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73855e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered list of data labels as per Fashion MNIST Documentation\n",
    "data_labels = [\n",
    "    \"T-Shirt\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle Boot\",\n",
    "]\n",
    "\n",
    "# Data pre-processing transformations\n",
    "transforms = Compose([ToTensor(), Normalize(mean=0.5, std=0.5)])\n",
    "\n",
    "# Initialise data\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transforms \n",
    ")\n",
    "\n",
    "# Train on 80%, reserve remainder for validation\n",
    "train_size = int(0.8 * len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "train_subset, val_subset = random_split(training_data, [train_size, val_size])\n",
    "\n",
    "# Batch Size (default = 64)\n",
    "batch_size = 64\n",
    "\n",
    "# Load the data with automatic shuffling for training/validation\n",
    "train_loader = DataLoader(train_subset, batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "val_images, val_labels = next(iter(val_loader))\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "# Tests\n",
    "train_expected_size = torch.Size([batch_size, 1, 28, 28])\n",
    "assert train_images.shape == train_expected_size\n",
    "\n",
    "val_expected_size = torch.Size([batch_size, 1, 28, 28])\n",
    "assert val_images.shape == val_expected_size\n",
    "\n",
    "expected_label_size = torch.Size([batch_size])\n",
    "assert train_labels.shape == expected_label_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07ff01",
   "metadata": {},
   "source": [
    "### Example Image with label\n",
    "Here we take the first image in one of our training batches and display using MatPlotLib, the title is its associated label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e10bd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of random sample with label\n",
    "img = train_images[0].squeeze()\n",
    "label = data_labels[train_labels[0]]\n",
    "\n",
    "fig = plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)\n",
    "plt.set_cmap(\"gray\")\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b9c38",
   "metadata": {},
   "source": [
    "## Building our ANN\n",
    "Using PyTorch it is very easy to create a simple network using global variables and nn.Sequential, however using a class will give us some flexibility in the width of our model while allowing for non-destructive testing to occur while optimising our network architecture.\n",
    "Furthermore, for the sake of comparison there exists 2 possible architectures within this class, one which contains dropout and another which does not. Initially, the linear model was tested using no dropout however as we will see below, we later implemented dropout to prevent overfitting from occuring during the training process.\n",
    "Each class we create inherits from the nn.Module class and requires an init function as well as a forward function which defines the forward pass of the network.\n",
    "\n",
    "### Init\n",
    "In the init function we first inherit everything from nn.Module and then specify our ReLU stack. This is defined using a series of linear perceptrons and ReLU activation layers. In the  case of using dropout, we also add dropout layers into the sequence between each layer. Additionally we also specify a flatten method which enables us to input the raw tensor data directly from the DataLoader without having to store the flattened image tensors as a global variable.\n",
    "For more information on the arguments see the comments in the code itself.\n",
    "\n",
    "### Forward\n",
    "This is very simple, it applies a forward pass to our model where we then apply Logarithmic Softmax to the output (as this is a classification task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52665704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for an MLP (dropout optional)\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden1,\n",
    "        hidden2,\n",
    "        hidden3,\n",
    "        in_features=28 * 28,\n",
    "        out_features=10,\n",
    "        use_dropout=False,\n",
    "        dropout_prob=0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Multi-Layer Perceptron with specifiable hidden layer widths and optional use of dropout\n",
    "        Args:\n",
    "            hidden1 (int): specify the number of neurons in layer 1\n",
    "            hidden2 (int): specify the number of neurons in layer 2\n",
    "            hidden3 (int): specify the number of neurons in layer 3\n",
    "            in_features (int/optional): specify the number of inputs (size of flattened image = length * width)\n",
    "            out_features (int/optional): specify the number of outputs (number of classes)\n",
    "            use_dropout (bool/optional): enable dropout\n",
    "            dropout_prob (float/option): specify dropout probability. (default = 0.2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        if use_dropout:\n",
    "            self.lin_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden1),\n",
    "                nn.BatchNorm1d(hidden1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(hidden1, hidden2),\n",
    "                nn.BatchNorm1d(hidden2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(hidden2, hidden3),\n",
    "                nn.BatchNorm1d(hidden3),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(hidden3, out_features),\n",
    "            )\n",
    "        else:\n",
    "            self.lin_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features, hidden1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden1, hidden2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden2, hidden3),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden3, out_features),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        output = self.lin_relu_stack(x)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35368bb",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "Much the same as with the ANN, we create a class to define our CNN. This also inherits from nn.Module. Unlike the ANN, we do not need to flatten our input data until we have passed it through the convolution layers.\n",
    "\n",
    "### Init\n",
    "Once again we inherit everything from the parent class nn.Module. Next we create a sequence of 2D-Convolution and MaxPool layers, a flatten method (identical to our ANN class) and a sequence of dense layers using ReLU as the activation functions. As a result of testing seen later in the notebook, Dropout and Batch Norm layers are also added in the dense layers.\n",
    "\n",
    "### Forward\n",
    "We define the forward pass by sending our input through the convolution stack before flattening this output. The flattened tensor is then, just as with the ANN sent through the dense layers before Log Softmax is applied and our output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cca6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN Architecture\n",
    "class CNNNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a simple Convolutional Neural Network with 2 convolution layers and 2 instances of MaxPooling. Dropout p=0.2 in the dense layers.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels. 1 for greyscale, 3 for rgb images etc.\n",
    "        out_channels (int): number of classes\n",
    "        filters1 (int): number of filters in convolution block 1\n",
    "        filters2 (int): number of filters in convolution block 2\n",
    "        kernel1 (int/tuple): kernel size in conv block 1\n",
    "        kernel2 (int/tuple): kernel size in conv block 2\n",
    "        stride1 (int): stride for conv block 1\n",
    "        stride2 (int): stride for conv block 2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        out_channels=10,\n",
    "        filters1=64,\n",
    "        filters2=128,\n",
    "        kernel1=3,\n",
    "        kernel2=3,\n",
    "        stride1=1,\n",
    "        stride2=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, filters1, kernel1, stride1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(filters1)\n",
    "        self.conv2 = nn.Conv2d(filters1, filters1, kernel1, stride1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(filters1)\n",
    "        self.max = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(filters1, filters2, kernel2, stride2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(filters2)\n",
    "        self.conv4 = nn.Conv2d(filters2, filters2, kernel2, stride2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(filters2)\n",
    "        self.gavgpool =     nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(filters2, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feature_map1 = F.relu(self.conv1(x))\n",
    "        output = self.bn1(self.feature_map1)\n",
    "        self.feature_map2 = F.relu(self.conv2(output))\n",
    "        output = self.bn2(self.feature_map2)\n",
    "        output = self.max(output)\n",
    "        self.feature_map3 = F.relu(self.conv3(output))\n",
    "        output = self.bn3(self.feature_map3)\n",
    "        self.feature_map4 = F.relu(self.conv4(output))\n",
    "        output = self.bn4(self.feature_map4)\n",
    "        output = self.max(output)\n",
    "        output = self.gavgpool(output)\n",
    "        output = self.flatten(output)\n",
    "        output = self.dense(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2d2a9",
   "metadata": {},
   "source": [
    "## Train/Test Functions\n",
    "Since we are defining multiple models, it would be nice to just write the code to train and test once, hence we will use a function here instead of global variables.\n",
    "### Train\n",
    "This function outlines the training process in any given epoch. We first enable training mode using the train() method, calculate the muber of batches and set our total loss to 0 (for a specified criterion).\n",
    "Now we iterate over all the items in our dataset using a for loop.\n",
    "We zero the gradient calculations before performing a forward pass of our model and calculating the loss. We then backpropagate using the backward() method and use the step() method to update the training parameters based on our optimiser. We finally add the training loss for every item before calculating the mean loss per batch. \n",
    "This value is then printed and returned.\n",
    "### Test\n",
    "Similar to the train function, however we need not specify an optimiser as we will not be updating any weights.\n",
    "The eval() method sets our model to evaluation mode, meaning parameters will not be updated as we iterate over the data. Since we are going to be recording accuracy we need both the number of batches and number of samples for our given dataloader. \n",
    "We perform the forward pass of our model with no gradients calculated but this time we also want to check if the prediction is correct so we can calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781bf958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train and test function for use with our models\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Perform a simple training pass for one epoch\n",
    "    Args:\n",
    "        dataloader (Dataloader(data)): Dataloader using torchvision\n",
    "        model (ANN/CNN): Chosen model\n",
    "        loss_fn: Loss function used\n",
    "        optimizer: optimiser used for gradient parameter adjustment\n",
    "    Returns:\n",
    "        train_loss (float): Average loss on dataloader\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    num_batch = len(dataloader)\n",
    "    train_loss = 0.0\n",
    "    for X, label in dataloader:\n",
    "        X, label = X.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= num_batch\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "    Perform a test pass.\n",
    "    Args:\n",
    "        dataloader (DataLoader(data)): Dataloader of a dataset using torchvision\n",
    "        model (ANN/CNN): Chosen model\n",
    "        loss_fn: Loss function\n",
    "    Returns:\n",
    "        test_loss (float): Average loss on dataloader\n",
    "        accuracy (float): Accuracy on dataloader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_batch = len(dataloader)\n",
    "    samples = len(dataloader.dataset)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, label in dataloader:\n",
    "            X, label = X.to(device), label.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, label)\n",
    "            test_loss += loss.item()\n",
    "            pred = pred.argmax(1)\n",
    "            correct += (pred == label).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batch\n",
    "    accuracy = correct / samples * 100\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644ab85",
   "metadata": {},
   "source": [
    "## Combining train and test\n",
    "Finally, we want to call a single function which can iterate our training and validation datasets over a specified number of epochs. To track our losses and accuracy we store these values in a list where each item in loss_hist is itself a list containing the training loss and the test loss, while accuracy_hist contains the accuracy of the model on the validation set after each epoch. After all epochs we pass the training set through the model also and store the test accuracy. We finally create a dictionary which contains all the history data and return it along with the test accuracy for use in plotting our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3ecc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test loop combined, we will use accuracy as our primary metric\n",
    "def run(train_loader, val_loader, test_loader, model, epochs, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Runs our model train and test loop for a specified number of epochs\n",
    "    Args:\n",
    "        rain_loader (Dataloader(data)): Training data\n",
    "        val_loader (Dataloader(data)): Validation data\n",
    "        test_loader (Dataloader(data)): Test data\n",
    "        model (MultilayerPerceptron): Model\n",
    "        epochs (int): Number of epochs\n",
    "    Returns:\n",
    "        history (dict): Dictionary with keys, epochs, train_loss, val_loss, accuracy_hist. Values are lists of length range(epochs)\n",
    "        test_accuracy (float): Accuracy on test loader\n",
    "    \"\"\"\n",
    "    train_loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    accuracy_hist = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch {e + 1}/{epochs}\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "        print(f\"Training loss = {train_loss:>5f}\")\n",
    "        val_loss, val_accuracy = test(val_loader, model, loss_fn)\n",
    "        print(f\"Validation loss = {val_loss:>5f} (Accuracy = {val_accuracy:.2f}%)\")\n",
    "        train_loss_hist.append(train_loss)\n",
    "        val_loss_hist.append(val_loss)\n",
    "        accuracy_hist.append(val_accuracy)\n",
    "\n",
    "    # Return test acc for final epoch\n",
    "    print(\"Switching to test set:\")\n",
    "    _, test_accuracy = test(test_loader, model, loss_fn)\n",
    "    print(f\"Final accuracy on test set: {test_accuracy:.2f}%\")\n",
    "    history = {\n",
    "        \"epoch\": range(epochs),\n",
    "        \"train_loss\": train_loss_hist,\n",
    "        \"val_loss\": val_loss_hist,\n",
    "        \"accuracy_hist\": accuracy_hist,\n",
    "    }\n",
    "    return history, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc153955",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "Similarly, since we are going to be reusing some code I will write a short function for preparing our data for plotting using seaborn and pandas. The DataFrame structure is very useful for storing our data such that we only need to call a single variable for different plots. To smooth out some of the plots I have decided that it would be of use to calculate rolling averages for the validation loss and accuracy history to use in comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7bde29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(result):\n",
    "    \"\"\"\n",
    "    Takes our outputs from run and prepares it for plotting.\n",
    "    Calculates a 3 epoch rolling average validation loss and 5 epoch rolling average validation accuracy\n",
    "    Args:\n",
    "        result (dict): Dictionary output from run function\n",
    "    Returns:\n",
    "        data (pd.DataFrame): Pandas dataframe for use with seaborn\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(result)\n",
    "    data[\"val_rolling\"] = data.val_loss.rolling(3).mean()\n",
    "    data[\"acc_rolling\"] = data.accuracy_hist.rolling(5).mean()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72563370",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "In addition, it is nice to visualise the confusion matrix for our models so we can easily identify potential shortcomings of our model, and also debug any potential issues. For example, I was consistently facing an issue where my model was unable to produce any predictions for index 6: \"Shirt\", caused by a bottleneck in network width. Without the use of the visualisation it was difficult to understand why my model had limited accuracy. As such visualising the results like this was very impactful in diagnosing issues with my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix plotter\n",
    "def ConfMatDisplay(dataloader, model):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix and plot\n",
    "    Args:\n",
    "        dataloader (Dataloader(data)): Option to use a custom dataloader for test data\n",
    "        model (ANN/CNN): Model\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data, label in dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        pred = pred.argmax(1)\n",
    "        predictions += pred.tolist()\n",
    "        labels += label.tolist()\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=data_labels)\n",
    "    disp.plot(xticks_rotation=\"vertical\", cmap=\"inferno\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3b304",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2f8a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomMetrics(dataloader,model,type):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    typelist = np.array([type for _ in range(10)])\n",
    "    metrics = {}\n",
    "    for data, label in dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        pred = pred.argmax(1)\n",
    "        predictions += pred.tolist()\n",
    "        labels += label.tolist()\n",
    "        typelist += type\n",
    "    metrics['precision'], metrics['recall'], metrics['f1_score'], _ = precision_recall_fscore_support(labels,predictions,average=None)\n",
    "    metrics['type'] = typelist\n",
    "    metrics['index'] = range(10)\n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021e3a2",
   "metadata": {},
   "source": [
    "## The first model\n",
    "Initially I had opted to use layer widths of 512,256,128 (as was used in the lab material), but as mentioned above, it led to issues with the model being unable to predict an entire category of label. Upon changing to values which are divisors of our input lengths (392,196,98), the performance of the model jumped with an increase in accuracy of around 10%. There is still a potential bottleneck in the output layer as we go from 98 inputs to just 10 outputs so further testing may show that a narrower model (or an addition layer with fewer neurons) will increase performance.\n",
    "### Hyperparameters\n",
    "To start we will use the fairly standard value of 0.001 as our learn rate and I decided on 30 epochs for training as it is ample time to highlight any major issues that occur during training while not taking too long to compute on my RTX 3070ti (around 5 minutes for the ANNs and 12 minutes for the CNN).\n",
    "### Loss function and Optimiser Choice\n",
    "We will be using Negative Log Likelihood as our loss function and Adam as our optimiser. We can also use Stochastic Gradient Descent (SGD), another good choice for classifier tasks and something we will see used in evaluation graphs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c608c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 392]         307,720\n",
      "              ReLU-3                  [-1, 392]               0\n",
      "            Linear-4                  [-1, 196]          77,028\n",
      "              ReLU-5                  [-1, 196]               0\n",
      "            Linear-6                   [-1, 98]          19,306\n",
      "              ReLU-7                   [-1, 98]               0\n",
      "            Linear-8                   [-1, 10]             990\n",
      "================================================================\n",
      "Total params: 405,044\n",
      "Trainable params: 405,044\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialise ANN and show structure\n",
    "ann_model = MultilayerPerceptron(392, 196, 98).to(device)\n",
    "summary(ann_model, input_size=(1, 28, 28))\n",
    "\n",
    "# Hyperparameters\n",
    "learn_rate = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "# initialise loss function and optimiser\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(ann_model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dce6db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Training loss = 0.537842\n",
      "Validation loss = 0.427038 (Accuracy = 84.49%)\n",
      "Epoch 2/30\n",
      "Training loss = 0.385842\n",
      "Validation loss = 0.378756 (Accuracy = 85.84%)\n",
      "Epoch 3/30\n",
      "Training loss = 0.345799\n",
      "Validation loss = 0.346416 (Accuracy = 87.06%)\n",
      "Epoch 4/30\n",
      "Training loss = 0.317045\n",
      "Validation loss = 0.332876 (Accuracy = 87.61%)\n",
      "Epoch 5/30\n",
      "Training loss = 0.294715\n",
      "Validation loss = 0.340169 (Accuracy = 87.82%)\n",
      "Epoch 6/30\n",
      "Training loss = 0.279419\n",
      "Validation loss = 0.319960 (Accuracy = 88.34%)\n",
      "Epoch 7/30\n",
      "Training loss = 0.264349\n",
      "Validation loss = 0.325238 (Accuracy = 88.72%)\n",
      "Epoch 8/30\n",
      "Training loss = 0.252542\n",
      "Validation loss = 0.307543 (Accuracy = 89.03%)\n",
      "Epoch 9/30\n",
      "Training loss = 0.237758\n",
      "Validation loss = 0.342054 (Accuracy = 87.78%)\n",
      "Epoch 10/30\n",
      "Training loss = 0.226555\n",
      "Validation loss = 0.316887 (Accuracy = 89.30%)\n",
      "Epoch 11/30\n",
      "Training loss = 0.215932\n",
      "Validation loss = 0.322016 (Accuracy = 89.05%)\n",
      "Epoch 12/30\n",
      "Training loss = 0.206706\n",
      "Validation loss = 0.335202 (Accuracy = 89.16%)\n",
      "Epoch 13/30\n",
      "Training loss = 0.196161\n",
      "Validation loss = 0.326456 (Accuracy = 89.31%)\n",
      "Epoch 14/30\n",
      "Training loss = 0.184742\n",
      "Validation loss = 0.342511 (Accuracy = 88.39%)\n",
      "Epoch 15/30\n",
      "Training loss = 0.178214\n",
      "Validation loss = 0.332872 (Accuracy = 89.47%)\n",
      "Epoch 16/30\n",
      "Training loss = 0.168800\n",
      "Validation loss = 0.370170 (Accuracy = 88.46%)\n",
      "Epoch 17/30\n",
      "Training loss = 0.163771\n",
      "Validation loss = 0.352871 (Accuracy = 89.05%)\n",
      "Epoch 18/30\n",
      "Training loss = 0.159199\n",
      "Validation loss = 0.359903 (Accuracy = 89.06%)\n",
      "Epoch 19/30\n",
      "Training loss = 0.148493\n",
      "Validation loss = 0.387485 (Accuracy = 89.27%)\n",
      "Epoch 20/30\n",
      "Training loss = 0.142390\n",
      "Validation loss = 0.361308 (Accuracy = 89.63%)\n",
      "Epoch 21/30\n",
      "Training loss = 0.136157\n",
      "Validation loss = 0.392016 (Accuracy = 89.72%)\n",
      "Epoch 22/30\n",
      "Training loss = 0.130738\n",
      "Validation loss = 0.390523 (Accuracy = 89.61%)\n",
      "Epoch 23/30\n",
      "Training loss = 0.128286\n",
      "Validation loss = 0.380650 (Accuracy = 89.45%)\n",
      "Epoch 24/30\n",
      "Training loss = 0.117164\n",
      "Validation loss = 0.406662 (Accuracy = 89.46%)\n",
      "Epoch 25/30\n",
      "Training loss = 0.114824\n",
      "Validation loss = 0.440046 (Accuracy = 88.88%)\n",
      "Epoch 26/30\n",
      "Training loss = 0.103260\n",
      "Validation loss = 0.450888 (Accuracy = 88.92%)\n",
      "Epoch 27/30\n",
      "Training loss = 0.111579\n",
      "Validation loss = 0.436333 (Accuracy = 89.28%)\n",
      "Epoch 28/30\n",
      "Training loss = 0.099203\n",
      "Validation loss = 0.470790 (Accuracy = 89.47%)\n",
      "Epoch 29/30\n",
      "Training loss = 0.100027\n",
      "Validation loss = 0.494751 (Accuracy = 89.16%)\n",
      "Epoch 30/30\n",
      "Training loss = 0.096393\n",
      "Validation loss = 0.494166 (Accuracy = 89.38%)\n",
      "Switching to test set:\n",
      "Final accuracy on test set: 88.73%\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model based on hyperparameters\n",
    "ann_hist, ann_test_accuracy = run(train_loader, val_loader, test_loader, ann_model, epochs, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c38b2d",
   "metadata": {},
   "source": [
    "### Plotting Losses\n",
    "From the above output it is useful to visualise the loss over time of our model to diagnose any potential issues. As we will see below, we see some significant overfitting occur as the validation loss begins to diverge after around 10 epochs. We will work to mitigate this in a number of ways as discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f36ecf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_data = PrepareData(ann_hist)\n",
    "# Plot relevant history\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=ann_data, x=\"epoch\", y=\"train_loss\", label=\"Training\")\n",
    "sns.lineplot(data=ann_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\")\n",
    "sns.lineplot(data=ann_data, x=\"epoch\", y=\"val_rolling\", label=\"Validation Rolling Avg.\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ANN Training Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8cb436",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Ideally we would have a value as close to 1000 as possible on the diagonal axis however what we can see here is there is a number of areas where the model fails to correctly classify the inputs. Intuitively this might make sense as the common erros are between categories such as 'Shirt', 'Tshirt', 'Coat' and 'Pullover,' which when considering the size of our input images seems like a reasonable error that even a human might make due to lack of detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrix for our first model\n",
    "ConfMatDisplay(test_loader, ann_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d58476",
   "metadata": {},
   "source": [
    "## Mitigating Overfitting\n",
    "Initial findings suggest a significant amount of overfitting occured during the training process. There is a number of ways we can deal with this, which we will implement in due course.\n",
    "### Dropout\n",
    "Dropout involves randomly disabling connections between layers at a fixed probability, in this case we will use p=0.2. Note that this only occurs during training as when we apply the model.eval() method, it disables dropout layers. The goal of this is to try and prevent the model from overoptimising on the training dataset, limiting its ability to predict unseen data accurately.\n",
    "### Batch Normalisation\n",
    "A further method we can use is through Batch Normalisation (BatchNorm). This aims to improve the stability of training by normalising each batch of input data, essentially performing a rescaling of inputs, much the same as we did by normalising the images when preprocessing our data.\n",
    "## Modified Model\n",
    "Considering the above, we will initalise a new model with the above two ideas implemented. For the sake of comparison all the other features are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88fa7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 392]         307,720\n",
      "       BatchNorm1d-3                  [-1, 392]             784\n",
      "              ReLU-4                  [-1, 392]               0\n",
      "           Dropout-5                  [-1, 392]               0\n",
      "            Linear-6                  [-1, 196]          77,028\n",
      "       BatchNorm1d-7                  [-1, 196]             392\n",
      "              ReLU-8                  [-1, 196]               0\n",
      "           Dropout-9                  [-1, 196]               0\n",
      "           Linear-10                   [-1, 98]          19,306\n",
      "      BatchNorm1d-11                   [-1, 98]             196\n",
      "             ReLU-12                   [-1, 98]               0\n",
      "          Dropout-13                   [-1, 98]               0\n",
      "           Linear-14                   [-1, 10]             990\n",
      "================================================================\n",
      "Total params: 406,416\n",
      "Trainable params: 406,416\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a new ANN with dropout for comparison\n",
    "ann_dropout = MultilayerPerceptron(392, 196, 98, use_dropout=True).to(device)\n",
    "summary(ann_dropout, input_size=(1, 28, 28))\n",
    "dropout_optimizer = torch.optim.Adam(ann_dropout.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad0353",
   "metadata": {},
   "source": [
    "We repeat the same process for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bf5141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Training loss = 0.545348\n",
      "Validation loss = 0.371714 (Accuracy = 86.21%)\n",
      "Epoch 2/30\n",
      "Training loss = 0.404018\n",
      "Validation loss = 0.346454 (Accuracy = 87.09%)\n",
      "Epoch 3/30\n",
      "Training loss = 0.367933\n",
      "Validation loss = 0.330836 (Accuracy = 87.69%)\n",
      "Epoch 4/30\n",
      "Training loss = 0.344181\n",
      "Validation loss = 0.325872 (Accuracy = 87.84%)\n",
      "Epoch 5/30\n",
      "Training loss = 0.319258\n",
      "Validation loss = 0.303912 (Accuracy = 89.09%)\n",
      "Epoch 6/30\n",
      "Training loss = 0.309382\n",
      "Validation loss = 0.301959 (Accuracy = 88.83%)\n",
      "Epoch 7/30\n",
      "Training loss = 0.296953\n",
      "Validation loss = 0.296174 (Accuracy = 88.76%)\n",
      "Epoch 8/30\n",
      "Training loss = 0.283907\n",
      "Validation loss = 0.289038 (Accuracy = 89.39%)\n",
      "Epoch 9/30\n",
      "Training loss = 0.270754\n",
      "Validation loss = 0.285881 (Accuracy = 89.66%)\n",
      "Epoch 10/30\n",
      "Training loss = 0.263556\n",
      "Validation loss = 0.282945 (Accuracy = 90.02%)\n",
      "Epoch 11/30\n",
      "Training loss = 0.252254\n",
      "Validation loss = 0.292552 (Accuracy = 89.51%)\n",
      "Epoch 12/30\n",
      "Training loss = 0.244912\n",
      "Validation loss = 0.273914 (Accuracy = 90.28%)\n",
      "Epoch 13/30\n",
      "Training loss = 0.237783\n",
      "Validation loss = 0.283740 (Accuracy = 89.89%)\n",
      "Epoch 14/30\n",
      "Training loss = 0.230999\n",
      "Validation loss = 0.282820 (Accuracy = 90.22%)\n",
      "Epoch 15/30\n",
      "Training loss = 0.223075\n",
      "Validation loss = 0.280010 (Accuracy = 89.93%)\n",
      "Epoch 16/30\n",
      "Training loss = 0.218156\n",
      "Validation loss = 0.279497 (Accuracy = 90.24%)\n",
      "Epoch 17/30\n",
      "Training loss = 0.209559\n",
      "Validation loss = 0.277882 (Accuracy = 90.52%)\n",
      "Epoch 18/30\n",
      "Training loss = 0.203211\n",
      "Validation loss = 0.302880 (Accuracy = 89.94%)\n",
      "Epoch 19/30\n",
      "Training loss = 0.199141\n",
      "Validation loss = 0.291432 (Accuracy = 89.90%)\n",
      "Epoch 20/30\n",
      "Training loss = 0.191687\n",
      "Validation loss = 0.287830 (Accuracy = 90.37%)\n",
      "Epoch 21/30\n",
      "Training loss = 0.188761\n",
      "Validation loss = 0.281138 (Accuracy = 90.30%)\n",
      "Epoch 22/30\n",
      "Training loss = 0.185127\n",
      "Validation loss = 0.289435 (Accuracy = 90.22%)\n",
      "Epoch 23/30\n",
      "Training loss = 0.179172\n",
      "Validation loss = 0.291987 (Accuracy = 90.34%)\n",
      "Epoch 24/30\n",
      "Training loss = 0.172404\n",
      "Validation loss = 0.298395 (Accuracy = 90.28%)\n",
      "Epoch 25/30\n",
      "Training loss = 0.170596\n",
      "Validation loss = 0.292783 (Accuracy = 90.44%)\n",
      "Epoch 26/30\n",
      "Training loss = 0.169117\n",
      "Validation loss = 0.295434 (Accuracy = 90.51%)\n",
      "Epoch 27/30\n",
      "Training loss = 0.163589\n",
      "Validation loss = 0.308433 (Accuracy = 90.12%)\n",
      "Epoch 28/30\n",
      "Training loss = 0.161283\n",
      "Validation loss = 0.295670 (Accuracy = 90.41%)\n",
      "Epoch 29/30\n",
      "Training loss = 0.156585\n",
      "Validation loss = 0.295014 (Accuracy = 90.52%)\n",
      "Epoch 30/30\n",
      "Training loss = 0.152059\n",
      "Validation loss = 0.304794 (Accuracy = 90.39%)\n",
      "Switching to test set:\n",
      "Final accuracy on test set: 89.53%\n"
     ]
    }
   ],
   "source": [
    "# Train and test\n",
    "dropout_hist, dropout_test_accuracy = run(train_loader,val_loader,test_loader,ann_dropout,epochs,loss_fn,dropout_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb5ac6",
   "metadata": {},
   "source": [
    "What we immediately notice from the outputs of our train/test functions is the loss values are much closer together and we only begin to see the impact of overfitting towards later epochs. What this does fully mitigate is the loss on the validation set diverging entirely so the model no longer becomes more incorrect with further training (at least  from our chosen epoch count). We can see a clear visual representation of this in the plot below:\n",
    "### Early Stopping\n",
    "What we might see now, especially as the validation loss essentially flatlines after around 15 epochs is that it might be beneficial to implement early stopping since the model doesn't noticably improve in performance on unseen data beyond this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_data = PrepareData(dropout_hist)\n",
    "\n",
    "# Plot relevant history\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=dropout_data, x=\"epoch\", y=\"train_loss\", label=\"Training\")\n",
    "sns.lineplot(data=dropout_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\")\n",
    "sns.lineplot(\n",
    "    data=dropout_data, x=\"epoch\", y=\"val_rolling\", label=\"Validation Rolling Avg.\"\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Modified ANN Training Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb45b1",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Test results are quite similar however it is still good to plot this for comparison with the original model, and in this instance there appears to be some noticable performance improvements of around 1-2% over the basic implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48486b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrix\n",
    "ConfMatDisplay(test_loader, ann_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186e037",
   "metadata": {},
   "source": [
    "## Visualising Model Output\n",
    "Now that we have a decent idea of 'what works' with respect to our ANN, it would be nice to visualise an example with the respective probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example (we choose a specific index since test data is unshuffled and also to show a split probability output)\n",
    "idx = 29\n",
    "test_image, test_label = test_images[idx].to(device), test_labels[idx].to(device)\n",
    "prob = torch.exp(ann_dropout(test_image))\n",
    "\n",
    "# Subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13, 6))\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].imshow(test_images[idx].cpu().numpy().squeeze())\n",
    "axes[0].set_title(data_labels[test_label.item()])\n",
    "prob_dist = axes[1].bar(range(10), prob.detach().cpu().numpy().squeeze())\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].set_xticklabels(data_labels, size=\"small\")\n",
    "axes[1].set_title(\"Label Probability (Modified ANN)\")\n",
    "axes[1].bar_label(prob_dist, fmt=\"{:.3f}\")\n",
    "plt.set_cmap(\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf51ba3",
   "metadata": {},
   "source": [
    "## Optimiser Choice\n",
    "We have used Adam for both of our models thusfar, however for the sake of comparison let us compare the impact of different optimisers on model performance. We will now create a copy of our existing modified ANN model, but try a few variations using SGD, RMSProp and Adagrad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define various models based on different optimisers\n",
    "ann_SGD = MultilayerPerceptron(392, 196, 98, use_dropout=True).to(device)\n",
    "SGD_optimizer = torch.optim.SGD(ann_SGD.parameters(), lr=learn_rate, momentum=0.9)\n",
    "ann_RMS = MultilayerPerceptron(392, 196, 98, use_dropout=True).to(device)\n",
    "RMS_optimizer = torch.optim.RMSprop(ann_RMS.parameters(), lr=learn_rate)\n",
    "ann_adagrad = MultilayerPerceptron(392, 196, 98, use_dropout=True).to(device)\n",
    "adagrad_optimizer = torch.optim.Adagrad(ann_adagrad.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae52a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test each\n",
    "SGD_hist, SGD_test_accuracy = run(train_loader, val_loader, test_loader, ann_SGD, epochs, loss_fn, SGD_optimizer)\n",
    "RMS_hist, RMS_test_accuracy = run(train_loader, val_loader, test_loader, ann_RMS, epochs, loss_fn, RMS_optimizer)\n",
    "adagrad_hist, adagrad_test_accuracy = run(train_loader,val_loader,test_loader,ann_adagrad,epochs,loss_fn,adagrad_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c86e8",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Immediate observations suggest that both Adam and RMSProp produce lower overall loss across both datasets, but especially on the training set suggesting it could be 'better' than SGD and Adagrad. Adagrad is particularly slow at converging, showing that training and validation loss have only just converged by 30 epochs, compared to this occuring at around 5-10 epochs in the case of the other 3. With that in mind Adagrad is probably not the right choice for us to use.\n",
    "To fully decide it may be a good idea to look into our other evaluation metrics to determine which is the best choice first but Adam still seems to be a strong contender at this point. It is also worth noting that the other optimisers may work better with adjusted hyperparameters, something we could tune using libraries such as Optuna and RayTune, however this may require some large adjustments to my train/test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b98b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "sgd_data = PrepareData(SGD_hist)\n",
    "rms_data = PrepareData(RMS_hist)\n",
    "adagrad_data = PrepareData(adagrad_hist)\n",
    "\n",
    "# Create subplots for each optimiser type\n",
    "fig2, axes2 = plt.subplots(nrows=1, ncols=4, sharex=True, sharey=True, figsize=(25, 5))\n",
    "sns.lineplot(ax=axes2[0], data=sgd_data, x=\"epoch\", y=\"train_loss\", label=\"Training\")\n",
    "sns.lineplot(ax=axes2[0], data=sgd_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\")\n",
    "sns.lineplot(ax=axes2[1], data=rms_data, x=\"epoch\", y=\"train_loss\", label=\"Training\")\n",
    "sns.lineplot(ax=axes2[1], data=rms_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\")\n",
    "sns.lineplot(\n",
    "    ax=axes2[2], data=adagrad_data, x=\"epoch\", y=\"train_loss\", label=\"Training\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axes2[2], data=adagrad_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axes2[3], data=dropout_data, x=\"epoch\", y=\"train_loss\", label=\"Training\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    ax=axes2[3], data=dropout_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\"\n",
    ")\n",
    "axes2[0].set_title(\"SGD\")\n",
    "axes2[1].set_title(\"RMSProp\")\n",
    "axes2[2].set_title(\"Adagrad\")\n",
    "axes2[3].set_title(\"Adam\")\n",
    "plt.suptitle(\"Optimiser Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f914eb1",
   "metadata": {},
   "source": [
    "### Evaluation Metric Comparison\n",
    "Looking at accuracy alone, it is clear to see that Adam produces the best performing model (note: training has been repeated multiple times to ensure this result) and as such will probably mean it remains our optimiser of choice moving forward with the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance comparison\n",
    "x = [\"Adam\", \"SGD\", \"Adagrad\", \"RMSProp\"]\n",
    "accuracy_data = [dropout_test_accuracy,SGD_test_accuracy,adagrad_test_accuracy,RMS_test_accuracy]\n",
    "barchart = plt.bar(x, accuracy_data)\n",
    "plt.bar_label(barchart, fmt=\"{:.2f}\")\n",
    "plt.ylim(87.5, 90)\n",
    "plt.xlabel(\"Optimiser\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2057ada",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Another way we can improve our model performance is through augmentation of our training data. This is by applying random transforms such as flips and rotations to the training data. In theory this would enable us to create a infinite training dataset (up to congrence) but for now we will just apply this once on another copy of our modified ANN. Below is an example of augmented data (the same image we used for comparison earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1def55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset transforms\n",
    "augment_transforms = Compose(\n",
    "    [\n",
    "        ToTensor(),\n",
    "        Normalize(0.5, 0.5),\n",
    "        RandomHorizontalFlip(0.5),\n",
    "        RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    ]\n",
    ")\n",
    "train_dataset_aug = datasets.FashionMNIST(\n",
    "    root=\"data\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=augment_transforms,\n",
    ")\n",
    "# New data split\n",
    "train_subset_aug, val_subset_aug = random_split(\n",
    "    train_dataset_aug, [train_size, val_size]\n",
    ")\n",
    "# New Loaders\n",
    "train_loader_augmented = DataLoader(train_subset_aug, batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader_aug = DataLoader(val_subset_aug, batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of augmented data\n",
    "augment = Compose(\n",
    "    [RandomHorizontalFlip(1.0), RandomAffine(degrees=10, translate=(0.1, 0.1))]\n",
    ")\n",
    "augmented_img = augment(test_image)\n",
    "fig3, axes3 = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axes3[0].axis(\"off\")\n",
    "axes3[1].axis(\"off\")\n",
    "axes3[0].imshow(test_image.cpu().squeeze(), cmap=\"gray\")\n",
    "axes3[1].imshow(augmented_img.cpu().squeeze(), cmap=\"gray\")\n",
    "axes3[0].set_title(\"Original\")\n",
    "axes3[1].set_title(\"Augmented\")\n",
    "plt.suptitle(\"Example of Augmented Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e17062",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_aug = MultilayerPerceptron(392, 196, 98, use_dropout=True).to(device)\n",
    "aug_optimizer = torch.optim.Adam(ann_aug.parameters(), lr=learn_rate)\n",
    "aug_hist, aug_test_accuracy = run(\n",
    "    train_loader_augmented,\n",
    "    val_loader_aug,\n",
    "    test_loader,\n",
    "    ann_aug,\n",
    "    epochs,\n",
    "    loss_fn,\n",
    "    aug_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrix\n",
    "ConfMatDisplay(test_loader, ann_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1eadd0",
   "metadata": {},
   "source": [
    "While only a small bump in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8a71b",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "We now implement our CNN, this will consist of 4 convolutional layers, 2 max pooling layers, a global average pooling layer before a set of 3 dense layers that occur after flattening the image tensor. For each convolution layer we apply zero padding to preserve the size of the tensor, this drastically increases compute cost but it should give us a more accurate model.\n",
    "Note that we apply our findings from above to add Batch Norm and Dropout layers in our network. We use the Adam as our optimiser as per our findings above and still use log softmax as our activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise with hyperparameters\n",
    "cnn = CNNNetwork(in_channels=1, out_channels=10, filters1=128, filters2=256).to(device)\n",
    "summary(cnn, input_size=(1, 28, 28))\n",
    "cnn_optimizer = torch.optim.Adam(cnn.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49247dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test\n",
    "cnn_hist, cnn_taccuracy = run(train_loader, val_loader, test_loader, cnn, epochs, loss_fn, cnn_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5958c7",
   "metadata": {},
   "source": [
    "## Visualising filters and feature maps\n",
    "Using the following function we are able to visualise both a sample of the filters and feature maps from our CNN after training, in this case we will call it just for the first layer, but we could feasibly do so for all 4 of the convolutional layers in the network (however this would require me to add compatibility for layer 3 and 4 with the use of an (el)if statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_filters(layer):\n",
    "    kernels = layer.weight.data.cpu().numpy()\n",
    "    fig, axes = plt.subplots(16, 8, figsize=(12, 12))\n",
    "    for i in range(kernels.shape[0]):\n",
    "        axes[i // 8, i % 8].imshow(kernels[i, 0], cmap=\"gray\")\n",
    "        axes[i // 8, i % 8].axis(\"off\")\n",
    "    plt.suptitle(\"Filters\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualise_feature_maps(feature_maps):\n",
    "    feature_maps = feature_maps.cpu().detach().numpy()\n",
    "    num_feature_maps = feature_maps.shape[1]\n",
    "    fig, axes = plt.subplots(16, 8, figsize=(12, 12))\n",
    "    for i in range(num_feature_maps):\n",
    "        axes[i // 8, i % 8].imshow(feature_maps[0, i, :, :], cmap=\"gray\")\n",
    "        axes[i // 8, i % 8].axis(\"off\")\n",
    "    plt.suptitle(\"Feature Maps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise filters in the first convolution layer\n",
    "visualise_filters(cnn.conv1)\n",
    "# visualise the feature maps after 2 convolutions\n",
    "visualise_feature_maps(cnn.feature_map2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2779894",
   "metadata": {},
   "source": [
    "### Loss evaluation and performance\n",
    "What is immediately obvious is that a CNN performs better than the ANNs as we are easily able to pass the 90% accuracy breakpoint. However, there is some evidence of overfitting occuring, likely due to a lack of dropout between the convolution layers. As such it may be wise to stop training after around 10 to 15 epochs as the model is likely to perform even better on unseen data after that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_data = PrepareData(cnn_hist)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=cnn_data, x=\"epoch\", y=\"train_loss\", label=\"Training\")\n",
    "sns.lineplot(data=cnn_data, x=\"epoch\", y=\"val_loss\", label=\"Validation\")\n",
    "sns.lineplot(data=cnn_data, x=\"epoch\", y=\"val_rolling\", label=\"Validation Rolling Avg.\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN Training Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce529051",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "We can see the CNN is the best perfomer so far, especially with regards to the problematic classification of shirts. There is a clear improvement in precision where we once again see an uplift in the minimum number of correct predictions. This is likely due to a CNN's ability to better store spatial information (by virtue of the structure of a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrix\n",
    "ConfMatDisplay(test_loader, cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa20e3",
   "metadata": {},
   "source": [
    "### Comparing Model Accuracy\n",
    "Below is a plot of the models' 5-epoch rolling average accuracy on the validation set in training. I note that there is only a small bump in accuracy when implementing dropout and batch norm in spite of how noticable the improvements to training stability are.\n",
    "\n",
    "The CNN is very clearly the 'winner' when it comes to classifying test data correctly, scoring around 2-3% better than our modified ANN. Additionally it reaches this point much faster than the ANNs, taking only around 15 epochs to peak in validation accuracy.\n",
    "\n",
    "The accuracy plot shows quite clearly where overfitting begins to take place as the gradients of our curves begin to reduce or in the case of the CNN even become negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae63f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparitive validation accuracy plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=ann_data, x=\"epoch\", y=\"acc_rolling\", label=\"ANN\")\n",
    "sns.lineplot(data=dropout_data, x=\"epoch\", y=\"acc_rolling\", label=\"Modified ANN\")\n",
    "sns.lineplot(data=cnn_data, x=\"epoch\", y=\"acc_rolling\", label=\"CNN\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.title(\"Validation Accuracy 5-Epoch Rolling Average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411868b8",
   "metadata": {},
   "source": [
    "## Comparing other metrics\n",
    "We can also compare the precision, recall and f1 score of our models using our CustomMetrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cd66f587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dropout_metrics = CustomMetrics(test_loader,ann_dropout,\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mann\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cnn_metrics = CustomMetrics(test_loader,\u001b[43mcnn\u001b[49m,\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m all_metrics = [dropout_metrics,cnn_metrics]\n\u001b[32m      4\u001b[39m all_metrics = pd.concat(all_metrics)\n",
      "\u001b[31mNameError\u001b[39m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "dropout_metrics = CustomMetrics(test_loader,ann_dropout,type='ann')\n",
    "cnn_metrics = CustomMetrics(test_loader,cnn,type='cnn')\n",
    "all_metrics = [dropout_metrics,cnn_metrics]\n",
    "all_metrics = pd.concat(all_metrics)\n",
    "\n",
    "fig4, axes4 = plt.subplots(1, 3, figsize=(24,8))\n",
    "sns.barplot(ax=axes4[0], data=all_metrics, x='index', y='precision',hue='type')\n",
    "axes4[0].set_xticks(range(10))\n",
    "axes4[0].set_xticklabels(data_labels, size='small')\n",
    "axes4[0].set_title('Precision')\n",
    "sns.barplot(ax=axes4[1], data=all_metrics, x='index', y='recall',hue='type')\n",
    "axes4[1].set_xticks(range(10))\n",
    "axes4[1].set_xticklabels(data_labels, size='small')\n",
    "axes4[1].set_title('Recall')\n",
    "sns.barplot(ax=axes4[2], data=all_metrics, x='index', y='f1_score',hue='type')\n",
    "axes4[2].set_xticks(range(10))\n",
    "axes4[2].set_xticklabels(data_labels, size='small')\n",
    "axes4[2].set_title('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c18fd2",
   "metadata": {},
   "source": [
    "## Closing Thoughts\n",
    "Overall, its quite clear to see the CNN performs far better than the ANNs do. While it comes at a computational cost, the higher accuracy is very noticable especially in the areas that the ANN struggles to predict correctly. If I were to further develop my models and testing methodology, I would want to implement early stopping in a formal way using a patience system, I note that this is very easy to do with tensorflow as there exists a built-in method for doing so. Data augmentation would also be useful for improving testing performance on unseen data. \n",
    "\n",
    "On reflection it would have been far easier to implement my project using tensorflow and keras, due to the existence of prebuilt train and test cycles amongst other useful methods, however I believe the depth of understanding I have gained as a result of using PyTorch (especially as I have minimal programming experience prior to this: some basic Python for first year maths and a little bit of R for numerical analysis) has helped me to feel much more comfortable with both python and coding in general."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
